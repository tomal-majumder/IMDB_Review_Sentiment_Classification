{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9e10d6b58cc643f5a3c5524c2efc491d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01629aa7e736433e87288b832dad57b1",
              "IPY_MODEL_bb231a765458481291169121b5eaaa7c",
              "IPY_MODEL_01a348cf845f4160b64c52b3858edadd"
            ],
            "layout": "IPY_MODEL_0163e736efc8491792fdcfc61cb4c09e"
          }
        },
        "01629aa7e736433e87288b832dad57b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66132d0ce4a143e28f2e276e392738bb",
            "placeholder": "​",
            "style": "IPY_MODEL_e1ccc289a6504b44bb3e5d9480a290dc",
            "value": "model.safetensors: 100%"
          }
        },
        "bb231a765458481291169121b5eaaa7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f11f4d13e24236aaca6afae4e16b14",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ba05e3680c24b4b8aed2f72cc1d6cc2",
            "value": 498818054
          }
        },
        "01a348cf845f4160b64c52b3858edadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821af544cfa043a2814387646dc43a3b",
            "placeholder": "​",
            "style": "IPY_MODEL_0547fb3490b14a06a8ffc5916ab93053",
            "value": " 499M/499M [00:06&lt;00:00, 97.0MB/s]"
          }
        },
        "0163e736efc8491792fdcfc61cb4c09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66132d0ce4a143e28f2e276e392738bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ccc289a6504b44bb3e5d9480a290dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03f11f4d13e24236aaca6afae4e16b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba05e3680c24b4b8aed2f72cc1d6cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "821af544cfa043a2814387646dc43a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0547fb3490b14a06a8ffc5916ab93053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10vJZ_Qa6c9n",
        "outputId": "1af5687e-3842-466e-85a6-5e393809fc12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    processed_review  label\n",
            "0  reviewer mention watch 1 oz episode ll hook ri...      1\n",
            "1  wonderful little production filming technique ...      1\n",
            "2  think wonderful way spend time hot summer week...      1\n",
            "3  basically family little boy jake think zombie ...      0\n",
            "4  petter mattei love time money visually stunnin...      1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the preprocessed data\n",
        "processed_df = pd.read_csv('/content/drive/MyDrive/Sentiment_Data/processed_reviews.csv')\n",
        "\n",
        "# Now you can work with the 'processed_df' DataFrame\n",
        "print(processed_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HiMSYkXnBJjZ",
        "outputId": "30d943a0-c135-4c82-caf4-8b5a00492a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    processed_review  label\n",
              "0  reviewer mention watch 1 oz episode ll hook ri...      1\n",
              "1  wonderful little production filming technique ...      1\n",
              "2  think wonderful way spend time hot summer week...      1\n",
              "3  basically family little boy jake think zombie ...      0\n",
              "4  petter mattei love time money visually stunnin...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-949d594a-d27d-4299-a12c-7948e7dc5169\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>processed_review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reviewer mention watch 1 oz episode ll hook ri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production filming technique ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>think wonderful way spend time hot summer week...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically family little boy jake think zombie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei love time money visually stunnin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-949d594a-d27d-4299-a12c-7948e7dc5169')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-949d594a-d27d-4299-a12c-7948e7dc5169 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-949d594a-d27d-4299-a12c-7948e7dc5169');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3cd6dd3e-6880-4221-b73b-a550485e6085\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3cd6dd3e-6880-4221-b73b-a550485e6085')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3cd6dd3e-6880-4221-b73b-a550485e6085 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "processed_df",
              "summary": "{\n  \"name\": \"processed_df\",\n  \"rows\": 49582,\n  \"fields\": [\n    {\n      \"column\": \"processed_review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49573,\n        \"samples\": [\n          \"george kim travel young son miles remote cabin upstate new york car hit deer swerve ditch mere occurrence misfortune mark beginning terrifying journey myth reality flesh eat spirit half animal half man wendigo haunt small town wendigo larry fessenden think provoke horror film tenderfoot somber family drama acting great character developed bone chill moment subtle glimpse wendigo handle effectively clear real imagine story take place entirely miles head overall wendigo contact larry fessenden work surely won film chance don mind watch unconventional 8 10\",\n          \"watch let rephrase suffer m fan eva don think flick ll head shoot photo like gangsta flix wasn close budget couldn dollar money probably spend caterer premise interesting victim die chance care win bother say isn worth effort m glad monthly rental plan local video store didn actually pay garbage oh flame love movie think lotta flix good jam jam tell need know\",\n          \"doubt beat street good film breakin scene spot clothe puma music importantly dancing storyline basic hey s tell story point film kid moment time matter show teenager general good matter everyday kid music dancing friendship having watch dvd recently plesantly surprised stand test time clothe didn look date possibly puma have massive comeback music sound fresh dancing captivate watch film 10 25 year age youth culture\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoConfig, AutoModelForMaskedLM, AutoTokenizer, RobertaTokenizer, RobertaConfig\n",
        "import transformers\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "config = AutoConfig.from_pretrained(\"roberta-base\")\n",
        "MAX_LEN = 512\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "# Dataset Analysis Functions\n",
        "def analyze_dataset_balance(df, label_column=\"label\"):\n",
        "    \"\"\"Analyze if the dataset is balanced and print statistics.\"\"\"\n",
        "    label_counts = df[label_column].value_counts()\n",
        "    total = len(df)\n",
        "\n",
        "    print(\"\\n=== Dataset Balance Analysis ===\")\n",
        "    for label, count in label_counts.items():\n",
        "        print(f\"Label {label}: {count} samples ({count/total*100:.2f}%)\")\n",
        "\n",
        "    # Calculate imbalance ratio\n",
        "    if len(label_counts) == 2:\n",
        "        imbalance_ratio = label_counts.max() / label_counts.min()\n",
        "        print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "        if imbalance_ratio > 2:\n",
        "            print(\"WARNING: Dataset is imbalanced (ratio > 2:1)\")\n",
        "            print(\"Consider using weighted loss function or sampling techniques\")\n",
        "\n",
        "    return label_counts\n",
        "\n",
        "def analyze_text_length(df, text_column=\"processed_review\"):\n",
        "    \"\"\"Analyze text length distribution.\"\"\"\n",
        "    df['text_length'] = df[text_column].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "    print(\"\\n=== Text Length Analysis ===\")\n",
        "    print(f\"Mean length: {df['text_length'].mean():.2f} words\")\n",
        "    print(f\"Median length: {df['text_length'].median()} words\")\n",
        "    print(f\"Max length: {df['text_length'].max()} words\")\n",
        "\n",
        "    # Check if we might be truncating too much\n",
        "    long_texts = (df['text_length'] > 400).sum()\n",
        "    print(f\"Texts longer than 400 words: {long_texts} ({long_texts/len(df)*100:.2f}%)\")\n",
        "\n",
        "    return df['text_length'].describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQEo72ARCNkQ",
        "outputId": "c0460805-e0a1-4d9d-d023-67c005487d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.comment_text = dataframe[\"processed_review\"].tolist()\n",
        "        self.targets = dataframe[\"label\"].tolist()\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        comment_text = str(self.comment_text[index])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        ids = inputs['input_ids'].squeeze()\n",
        "        mask = inputs['attention_mask'].squeeze()\n",
        "        token_type_ids = inputs[\"token_type_ids\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            'ids': ids,\n",
        "            'mask': mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = transformers.RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.l2 = torch.nn.Dropout(0.2)\n",
        "        self.l3 = torch.nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        # Pass attention_mask explicitly to address the warning\n",
        "        output_1 = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "        output_2 = self.l2(output_1.pooler_output)  # Using the pooler_output\n",
        "        output = self.l3(output_2)\n",
        "        return output\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "    \"\"\"Evaluate the model on the given dataloader.\"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            ids = data['ids'].to(device, dtype=torch.long)\n",
        "            mask = data['mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].cpu().numpy()\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            outputs = torch.sigmoid(outputs.squeeze()).cpu().numpy()\n",
        "\n",
        "            predictions.extend((outputs > 0.5).astype(int))\n",
        "            actual_labels.extend(targets.astype(int))\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(actual_labels, predictions)\n",
        "    f1 = f1_score(actual_labels, predictions)\n",
        "    precision = precision_score(actual_labels, predictions)\n",
        "    recall = recall_score(actual_labels, predictions)\n",
        "\n",
        "    print(\"\\n=== Evaluation Results ===\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure processed_df is available\n",
        "    # This is a placeholder - replace with your actual data loading\n",
        "    try:\n",
        "        print(\"Working with existing processed_df...\")\n",
        "        # Analyze dataset balance\n",
        "        analyze_dataset_balance(processed_df)\n",
        "        analyze_text_length(processed_df)\n",
        "    except NameError:\n",
        "        print(\"Warning: processed_df not found. Replace this with your actual data loading code.\")\n",
        "        # If you need to load the dataset here, uncomment and modify the line below:\n",
        "        # processed_df = pd.read_csv('your_data.csv')\n",
        "\n",
        "    # Your original train/test split\n",
        "    train_size = 0.7\n",
        "    train_dataset = processed_df.sample(frac=train_size, random_state=42)\n",
        "    test_dataset = processed_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "    print(\"FULL Dataset: {}\".format(processed_df.shape))\n",
        "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "    print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "    # Create datasets\n",
        "    training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "    testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "    # Increased batch size and optimized dataloader parameters\n",
        "    TRAIN_BATCH_SIZE = 32  # Increased from 5 to 32\n",
        "    VALID_BATCH_SIZE = 32  # Increased from 1 to 32\n",
        "\n",
        "    train_params = {\n",
        "        'batch_size': TRAIN_BATCH_SIZE,\n",
        "        'shuffle': True,\n",
        "        'num_workers': 4,  # Increased from 0 to 4\n",
        "        'pin_memory': True  # Added for faster data transfer to GPU\n",
        "    }\n",
        "\n",
        "    test_params = {\n",
        "        'batch_size': VALID_BATCH_SIZE,\n",
        "        'shuffle': False,  # No need to shuffle test data\n",
        "        'num_workers': 4,\n",
        "        'pin_memory': True\n",
        "    }\n",
        "\n",
        "    train_dataloader = DataLoader(training_set, **train_params)\n",
        "    testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "    # Initialize model\n",
        "    model = BERTClass()\n",
        "    model.to(device)\n",
        "\n",
        "    # Gradient accumulation steps\n",
        "    ACCUMULATION_STEPS = 2  # Effective batch size = 32 * 2 = 64\n",
        "\n",
        "    # Improved optimizer with weight decay\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    total_steps = len(train_dataloader) * 3 // ACCUMULATION_STEPS  # 3 epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=total_steps // 10,  # 10% warmup\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Loss function\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Initialize mixed precision training\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # Training loop\n",
        "    EPOCHS = 3\n",
        "    best_f1 = 0\n",
        "\n",
        "    # Calculate approximate time\n",
        "    steps_per_epoch = len(train_dataloader)\n",
        "    updates_per_epoch = steps_per_epoch // ACCUMULATION_STEPS\n",
        "    total_updates = updates_per_epoch * EPOCHS\n",
        "\n",
        "    print(f\"\\nTraining Configuration:\")\n",
        "    print(f\"- Train samples: {len(train_dataset)}\")\n",
        "    print(f\"- Batch size: {TRAIN_BATCH_SIZE}\")\n",
        "    print(f\"- Gradient accumulation steps: {ACCUMULATION_STEPS}\")\n",
        "    print(f\"- Effective batch size: {TRAIN_BATCH_SIZE * ACCUMULATION_STEPS}\")\n",
        "    print(f\"- Steps per epoch: {steps_per_epoch}\")\n",
        "    print(f\"- Optimizer updates per epoch: {updates_per_epoch}\")\n",
        "    print(f\"- Total optimizer updates for {EPOCHS} epochs: {total_updates}\")\n",
        "    print(f\"- Using mixed precision: Yes\")\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"EPOCH {epoch+1}/{EPOCHS}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader),\n",
        "                           desc=f\"Epoch {epoch+1} Training\")\n",
        "\n",
        "        for i, data in progress_bar:\n",
        "            ids = data['ids'].to(device, dtype=torch.long)\n",
        "            mask = data['mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "            # Mixed precision training\n",
        "            with autocast():\n",
        "                outputs = model(ids, mask, token_type_ids)\n",
        "                loss = loss_fn(outputs.squeeze(), targets)\n",
        "                loss = loss / ACCUMULATION_STEPS  # Normalize loss for accumulation\n",
        "\n",
        "            # Scale loss and accumulate gradients\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Update only after accumulation steps\n",
        "            if (i + 1) % ACCUMULATION_STEPS == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item() * ACCUMULATION_STEPS\n",
        "            progress_bar.set_postfix({'loss': total_loss / (i+1)})\n",
        "\n",
        "        # Make sure to update for the last batch if dataset size is not a multiple of ACCUMULATION_STEPS\n",
        "        if len(train_dataloader) % ACCUMULATION_STEPS != 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Evaluation\n",
        "        metrics = evaluate(model, testing_loader)\n",
        "\n",
        "        # Save best model\n",
        "        if metrics['f1'] > best_f1:\n",
        "            best_f1 = metrics['f1']\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/Sentiment_Data/best_model.pt\")\n",
        "            print(f\"New best model saved with F1: {best_f1:.4f}\")\n",
        "\n",
        "    print(\"\\nTraining completed!\")\n",
        "    print(f\"Best F1 Score: {best_f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9e10d6b58cc643f5a3c5524c2efc491d",
            "01629aa7e736433e87288b832dad57b1",
            "bb231a765458481291169121b5eaaa7c",
            "01a348cf845f4160b64c52b3858edadd",
            "0163e736efc8491792fdcfc61cb4c09e",
            "66132d0ce4a143e28f2e276e392738bb",
            "e1ccc289a6504b44bb3e5d9480a290dc",
            "03f11f4d13e24236aaca6afae4e16b14",
            "8ba05e3680c24b4b8aed2f72cc1d6cc2",
            "821af544cfa043a2814387646dc43a3b",
            "0547fb3490b14a06a8ffc5916ab93053"
          ]
        },
        "id": "hBdvra_uCb7K",
        "outputId": "8877948f-0684-4932-b5d9-0095263ef37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with existing processed_df...\n",
            "\n",
            "=== Dataset Balance Analysis ===\n",
            "Label 1: 24884 samples (50.19%)\n",
            "Label 0: 24698 samples (49.81%)\n",
            "Imbalance ratio: 1.01:1\n",
            "\n",
            "=== Text Length Analysis ===\n",
            "Mean length: 105.84 words\n",
            "Median length: 78.0 words\n",
            "Max length: 1297 words\n",
            "Texts longer than 400 words: 614 (1.24%)\n",
            "FULL Dataset: (49582, 3)\n",
            "TRAIN Dataset: (34707, 3)\n",
            "TEST Dataset: (14875, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e10d6b58cc643f5a3c5524c2efc491d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Configuration:\n",
            "- Train samples: 34707\n",
            "- Batch size: 32\n",
            "- Gradient accumulation steps: 2\n",
            "- Effective batch size: 64\n",
            "- Steps per epoch: 1085\n",
            "- Optimizer updates per epoch: 542\n",
            "- Total optimizer updates for 3 epochs: 1626\n",
            "- Using mixed precision: Yes\n",
            "\n",
            "==================================================\n",
            "EPOCH 1/3\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-599505da14dc>:159: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1 Training:   0%|          | 0/1085 [00:00<?, ?it/s]<ipython-input-9-599505da14dc>:199: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1 Training: 100%|██████████| 1085/1085 [12:35<00:00,  1.44it/s, loss=0.338]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.3383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465/465 [06:48<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluation Results ===\n",
            "Accuracy: 0.9072\n",
            "F1 Score: 0.9067\n",
            "Precision: 0.9138\n",
            "Recall: 0.8997\n",
            "New best model saved with F1: 0.9067\n",
            "\n",
            "==================================================\n",
            "EPOCH 2/3\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 2 Training:   0%|          | 0/1085 [00:00<?, ?it/s]<ipython-input-9-599505da14dc>:199: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 2 Training: 100%|██████████| 1085/1085 [12:38<00:00,  1.43it/s, loss=0.203]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.2032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465/465 [06:47<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluation Results ===\n",
            "Accuracy: 0.9146\n",
            "F1 Score: 0.9172\n",
            "Precision: 0.8923\n",
            "Recall: 0.9436\n",
            "New best model saved with F1: 0.9172\n",
            "\n",
            "==================================================\n",
            "EPOCH 3/3\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 3 Training:   0%|          | 0/1085 [00:00<?, ?it/s]<ipython-input-9-599505da14dc>:199: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 3 Training: 100%|██████████| 1085/1085 [12:38<00:00,  1.43it/s, loss=0.151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.1511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 465/465 [06:46<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluation Results ===\n",
            "Accuracy: 0.9213\n",
            "F1 Score: 0.9221\n",
            "Precision: 0.9157\n",
            "Recall: 0.9286\n",
            "New best model saved with F1: 0.9221\n",
            "\n",
            "Training completed!\n",
            "Best F1 Score: 0.9221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Load best model and final evaluation\n",
        "    model.load_state_dict(torch.load(\"/content/drive/MyDrive/Sentiment_Data/best_model.pt\"))\n",
        "    print(\"\\nFinal evaluation with best model:\")\n",
        "    final_metrics = evaluate(model, testing_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Qc1j4TEL33",
        "outputId": "5bfefc41-c480-481a-af18-4f52d9b8e641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final evaluation with best model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/465 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|██████████| 465/465 [06:48<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluation Results ===\n",
            "Accuracy: 0.9213\n",
            "F1 Score: 0.9221\n",
            "Precision: 0.9157\n",
            "Recall: 0.9286\n"
          ]
        }
      ]
    }
  ]
}